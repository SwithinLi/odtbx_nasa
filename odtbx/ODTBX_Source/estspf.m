function varargout = estspf(varargin)
% ESTSPF  Sigma-Point Filter. 
%   ESTSPF implements the square root form of the additive divided 
%   difference sigma point filter (ADDSPF).  Since the SPF is fundamentally
%   a discrete filter, it does not use any gradient information.  The 
%   required user-supplied functions are the discrete propagation and the 
%   discrete measurement and are different from the user-supplied dynamics
%   and measurement functions used in the other estimation functions ESTSEQ
%   and ESTBAT.
%
%   [T,X,P] = ESTSPF(PROPFUN,MEASFUN,TSPAN,X0,P0) with TSPAN = [T0 TFINAL]
%   propagates the discrete system model x(k)=f(x(k-1),t(k-1))+w(k-1) from 
%   T0 to TFINAL with initial conditions X0, then at TFINAL updates x with 
%   the measurement generated by y(k) = h(t(k),x(k)) + v(k) using an 
%   additive divided difference sigma point filter (ADDSPF).  To obtain 
%   updates at multiple times T1, T2, ..., TFINAL, use 
%   TSPAN = [T0 T1 T2 ... TFINAL].
%
%   The calling signature for PROPFUN is
% 
%     [xk1,rtQd] = propfun([tk tk1], xk, proparg)
% 
%   where xk1 is the column state vector at time tk1; rtQd is the square 
%   root of the discrete process noise covariance computed as the transpose 
%   of the Cholesky factorization: chol(Qd)'; xk is the state vector at 
%   time tk; and proparg is an input argument of the propagation function.
%
%   The calling signature for MEASFUN is
%
%     [yk,rtR] = measfun(tk, xk, measarg)
%
%   where yk is the column measurement vector at time tk; rtR is the 
%   square root of the measurement noise covariance computed as the 
%   transpose of the Cholesky factorization: chol(R)'; and measarg is an
%   input argument of the measurement function.
%
%   To specify differences between the true and the estimator models of the
%   propagation and the measurement, the user can specify PROPFUN and/or 
%   MEASFUN as structures, whose fields are *.tru and *.est. The function 
%   specified in *.tru will be used to evaluate the true state, and the one 
%   in *.est will be used for the estimator.  Similar conventions may be 
%   used for X0, PROPARG, and MEASARG, i.e. X0.Xo and X0.Xbaro, 
%   PROPARG.tru and MEASARG.tru, PROPARG.tru and MEASARG.est.
% 
%   The outputs T, X, and P are cell arrays of the time, the estimates and 
%   the corresponding covariances.  Each element of the cell array 
%   represents a Monte Carlo case.  The columns in the solution array X{i} 
%   and the columns in the covariance P{i} correspond to times returned in 
%   the row vector T{i}.  The columns of P{i} correspond to the unique lower
%   triangular elements and the full matrix can be reformed using
%   UNSCRUNCH(P(:,i)).
%
%   P0 specifies the initial covariance of the states.  The difference in 
%   the true and the estimator can be specified with a structure: P0.Po 
%   and P0.Pbaro.
%
%   [T,X,P] = ESTSPF(PROPFUN,MEASFUN,TSPAN,X0,P0,OPTIONS) performs as above
%   with default properties replaced by values in OPTIONS, an argument
%   created with the SETODTBXOPTIONS function.  See ODTBXOPTIONS for
%   details. Commonly used options allow one to specify parameters or
%   features of the estimator, force model, and measurment model. 
%
%   [T,X,P] = ESTSPF(PROPFUN,MEASFUN,TSPAN,X0,P0,OPTIONS,PROPARG,MEASARG)
%   passes PROPARG to PROPFUN and MEASARG to MEASFUN as PROPFUN(TV,X,PROPARG) 
%   and MEASFUN(T,X,MEASARG), respectively.  Use OPTIONS = [] as a place 
%   holder if no options are set.
%
%   [T,X,P] = ESTSPF(PROPFUN,MEASFUN,TSPAN,X0,P0,OPTIONS,PROPARG,MEASARG,S,C)
%   passes in solve-for and consider mapping matrices, S and C,
%   respectively.  These matrices partition the state into a solve-for
%   partition, S*x, and a consider partition, C*x.  Only parameters in the
%   former partition will be updated from the meaurements.  To handle the
%   different dimensions of the full state vs. the solve-for and consider
%   partitions, the user can either design PROPFUN and MEASFUN to check for
%   this, or specify PROPFUN and/or MEASFUN as structures, whose fields are
%   *.tru and *.est. The function specified in *.tru will be used to
%   evaluate the full state, and the one in *.est will be used for the
%   solve-for partition.  Use [] as a place holder for OPTIONS, PROPARG, 
%   and/or MEASARG as necessary if these inputs are not required.
%
%   [T,X,P,E] = ESTSPF(PROPFUN,MEASFUN,TSPAN,X0,P0,...) also returns the
%   estimation errors cell array, E.
%
%   [T,X,P,E,DY] = ESTSPF(PROPFUN,MEASFUN,TSPAN,X0,P0,...) also returns the
%   innovations, DY.
%
%   [T,X,P,E,DY,PA,PV,PW,PHATA,PHATV,PHATW] = ESTSPF(...) returns several
%   addditional covariances: PA, PV, and PW are the true
%   covariances that arise only from the true  _a priori_ covariance, the
%   true measurement noise covariance, and the true process noise
%   covariance, respectively;  PHATA, PHATV, PHATW are the estimator's
%   covariances that arise only from the design values of the  _a priori_
%   covariance, the measurement noise covariance, and the process noise
%   covariance.  These covariances are 3D arrays with the third column 
%   representing the time vector that correspond to the time vector of the 
%   first Monte Carlo case T{1}.
%
%   [T,X,P,E,DY,PA,PV,PW,PHATA,PHATV,PHATW,EFLAG,PDY] = ESTSPF(...) returns 
%   the edit flag and the measurement innovations covariance that were 
%   returned from the Monte Carlo simulations.
%
%   If multiple monte-carlo cases are specified using SETODTBXOPTIONS, 
%   this is capable of running the monte-carlo cases in parallel.  Simply
%   open a pool of parallel workers using 'matlabpool' and estspf will
%   utilize them.  The only contraints placed on the caller when running
%   monte-carlo cases in parallel are:
%    1. the dynfun and datafun functions must not retain state that later 
%       monte-carlo runs will rely on
%    2. any Java classes used must be serializable
%    3. any variables that are used in the dynfun or datafun functions but
%       are setup before the call to estspf must appear somehwhere in the 
%       setup code (e.g. setting up a variable by loading it from a file 
%       will assign it a value without the variable name ever appearing in 
%       the code - this will cause an error in parallel execution)
%
%   EXAMPLE:
%
%       % Propagation function for true and estimate
%       function [Xnext,rtQd] = rwprop(tspan,Xcurr,q)
%       dt = tspan(2)-tspan(1);
%       Xnext = Xcurr;
%       rtQd = sqrt(q*dt);
%
%       % Measurement function for true and estimate
%       function [Y,rtR] = rwmeas(t,X,var)
%       Y = X;
%       rtR = var;
%
%       opt=setOdtbxOptions('MonteCarloCases',125);      
%       P0.Po = 10;
%       P0.Pbaro = 10;
%       XO.Xo = 0;
%       X0.Xbaro = 0;
%       proparg.tru = 1; % Process Noise PSD
%       proparg.est = 0; % Process Noise PSD
%       measarg.tru = 1; % Measurement Noise variance
%       measarg.est = 1; % Measurement Noise variance
%
%       [T,X,P] = estspf(@rwprop,@rwmeas,[1:5],X0,P0,opt,proparg,measarg);
%
%   keyword: Estimation,
%
%   See also
%      options handling:      ODTBXOPTIONS, SETODTBXOPTIONS,
%                             GETODTBXOPTIONS
%      plotting solutions:    VARPILES
%      other ODEAS filters:   ESTBAT, ESTSEQ
%
% (This file is part of ODTBX, The Orbit Determination Toolbox, and is
%  distributed under the NASA Open Source Agreement.  See file source for
%  more details.)

% ODTBX: Orbit Determination Toolbox
% 
% Copyright (c) 2003-2011 United States Government as represented by the
% administrator of the National Aeronautics and Space Administration. All
% Other Rights Reserved.
% 
% This file is distributed "as is", without any warranty, as part of the
% ODTBX. ODTBX is free software; you can redistribute it and/or modify it
% under the terms of the NASA Open Source Agreement, version 1.3 or later.
% 
% You should have received a copy of the NASA Open Source Agreement along
% with this program (in a file named License.txt); if not, write to the 
% NASA Goddard Space Flight Center at opensource@gsfc.nasa.gov.

% Russell Carpenter
% NASA Goddard Space Flight Center
%
% NOTE: The interface design of this function is based on ODE45.M, which
% is copyrighted by The MathWorks, Inc.
%
% Modification History
% ---------------------
% 2009 May 26  Sun Hur-Diaz  
%   Cleaned up bugs, comments, selftests, examples.  Also added the DY output
%   and changed the variance outputs to covariance outputs.
%
% 2009 Sept 14 Sun Hur-Diaz
%   Corrected the true covariance saves to correspond to the full covariance
%   and not just for the solve-for.
%
% 2009 Oct 20 Sun Hur-Diaz
%   Modified the internal function fixomc to also fix the gain matrix as 
%   well whereby the elements of the gain matrix corresponding to
%   measurements that are NaN are set to zero.  This essentially inhibits
%   the covariance update due to those particular measurements.
%
% 2010 May 11 Sun Hur-Diaz
%   Changed the name of fixomc to fixgain and removed the zeroing of the
%   innovations.
% 
% 2010 Sept 16 Sun Hur-Diaz
%   Added measurement editing capability
%
% 2013 May 3 Ravi Mathur
%   Fully extracted regression test to estspf_test.
%   Added ability to specify separate truth & estimated options structures 
%     for the options input.

%% ESTSPF: Addititive Divided Difference Sigma Point Filter
%
% ESTSPF is part of the OD Toolbox.  It allows for the analysis of additive
% divided difference sigma point filters, based on the generalized
% covariance analysis method of Markley, et al. (F. L. Markley, E.
% Seidewitz, and M. Nicholson, "A General Model for Attitude Determination
% Error Analysis,"  _NASA Conference Publication 3011: Flight
% Mechanics/Estimation Theory Symposium_, May 1988, pp. 3-25, and F. L.
% Markley, E. Seidewitz, and J. Deutschmann, "Attitude Determination Error
% Analysis: General Model and Specific Application,"  _Proceedings of the
% CNES Space Dynamics Conference_, Toulouse, France, November 1989, pp.
% 251-266).
%
% The additive divided difference sigma point filter is a sigma point
% filter with second-order numerical difference approximations of the
% nonlinear dynamics and measurement models with the assumption that the
% process and measurement noise enter the system additively.  The
% implementation of the filter in this function is based on the analysis by
% Lee and Alfriend. (D.-J. Lee and K. T. Alfriend, "Additive Divided
% Difference Filtering for Attitude Estimation Using Modified Rodrigues
% Parameters," _Proceedings of the F. Landis Markley Astronautics Symposium_,
% edited by J. L. Crassidis et al, Vol. 132 of _Advances in the
% Astronauctical Sciences_, American Astronautical Society, Univelt, 2008.)
%
% The following mathematical specifications were published from comments
% embedded within the m-file.

%% Input Parsing and Setup
% Parse the input list and options structure.  Pre-allocate arrays, using a
% cell index for the monte carlo cases, which will avoid the need for each
% case to have time series at common sample times.  Use an extra dimension
% "on the right" within each monte carlo case to accomodate the time
% series, which will avoid the need for conversions from cell to double for
% plotting.  Where it makes sense, use cell indices to partition
% large matrices into submatrices, to avoid the need for opaque indexing
% computations.
%
% TODO: This should be a subfunction, or if there is a lot of commonality with
% estseq's version, a private function.
%
% The full self-test has been extracted to estspf_test.m to conform to
% the new regression testing framework.
%
% If there are no output arguments, then plot the results of a particular
% input as a demo.

if nargin >= 5, % ESTSPF(PROPFUN,MEASFUN,TSPAN,X0,P0...)
    if all(isfield(varargin{1}, {'tru','est'})),
        propfun = varargin{1};
    else
        propfun.tru = varargin{1};
        propfun.est = varargin{1};
    end
    if all(isfield(varargin{2}, {'tru','est'})),
        measfun = varargin{2};
    else
        measfun.tru = varargin{2};
        measfun.est = varargin{2};
    end
    tspan = varargin{3};
    if isstruct(varargin{4}),
        Xo = varargin{4}.Xo;
        Xbaro = varargin{4}.Xbaro;
    else
        Xo = varargin{4};
        Xbaro = varargin{4};
    end
    if isstruct(varargin{5}),
        Po = varargin{5}.Po;
        Pbaro = varargin{5}.Pbaro;
    else
        Po = varargin{5};
        Pbaro = varargin{5};
    end
    if isempty(Po) || isempty(Pbaro)
        error('Initial covariance must be set!')
    end
elseif nargin ~= 0 && nargin ~= 1,
    error('There must be at least 5 inputs! (propfun,measfun,tspan,X0,PO)')
end
if nargin >=6,
    options = varargin{6};
else
    options = setOdtbxOptions('OdeSolvOpts',odeset);
end
ncases = getOdtbxOptions(options,'MonteCarloCases',1); % Set to at least 1

if nargin >= 7,
    if all(isfield(varargin{7}, {'tru','est'}))
        proparg = varargin{7};
    else
        proparg.tru = varargin{7};
        proparg.est = varargin{7};
    end
elseif nargin >= 5,
    proparg.tru = [];
    proparg.est = [];
end
if nargin >= 8,
    if all(isfield(varargin{8}, {'tru','est'}))
        measarg = varargin{8};
    else
        measarg.tru = varargin{8};
        measarg.est = varargin{8};
    end
elseif nargin >= 5,
    measarg.tru = [];
    measarg.est = [];
end
if nargin >= 9,
    if isa(varargin{9},'function_handle'),
        mapfun = varargin{9}; %#ok<NASGU> %TODO
    elseif isa(varargin{9},'numeric') % constant solve-for map
        S = varargin{9};
        C = []; %zeros(0,0,length(tspan)); % in case C is not input, solve for all states
    end
elseif nargin >= 5, % If S & C not input, solve for all states
    S = eye(size(Po));
    C = []; %zeros(0,0,length(tspan));
end
if nargin >= 10, % constant consider map
    C = varargin{10}; %repmat(varargin{10},[1,1,length(tspan)]);
end
if nargout == 0,
    demomode = true; % Automatically generate output plots
    ksig = 2;
else
    demomode = false;
end

%% Covariance and Monte Carlo Analysis
% Perform a general covariance analysis of the ADDSPF. Assume that design
% values and true values may differ for the initial covariance, measurement
% noise covariance, and process noise covariance. Assume that the process
% and measurement noise covariances may be time-varying. Assume that
% linear, possibly time-varying, transformations partition the state space
% into a "solve-for" subspace which is to be estimated from the
% measurements, and a "consider" subspace which will not be estimated.
% Compute the contributions due to _a priori_ uncertainty, measurement
% noise, and process noise. 
%   Always perform at least one actual simulation as a check against 
% linearization problems.  Generate random deviations from the reference as 
% initial conditions for each monte carlo case.  Propagate each deviated 
% case, and use this as truth for measurement simulation and estimation 
% error generation.  Do any remaining cases after plotting the covariance 
% results, so the user can terminate the run if obvious problems occur, 
% since the simulation may be slow, especially if a lot of monte carlo 
% cases are running.

%%
% *Solve-For and Consider Mapping*
%
% The mapping of the state-space into solve-for and consider subspaces is
% defined according to
%
% $$ s(t) = S(t) x(t), \quad c(t) = C(t) x(t) $$
%
% $$ M(t) = \Bigl[ S(t);\, C(t) \Bigr], \quad
% M^{-1}(t) = \Bigl[ \tilde{S}(t)\, \tilde{C}(t) \Bigr]$$
%
% $$ x(t) = \tilde{S}(t) s(t) + \tilde{C}(t) c(t) $$% Determine the number of measurements

ytemp = feval(measfun.tru,tspan(1),Xo,measarg.tru);
nmeas = length(ytemp);

% Get montecarloseed and edit options
eopts = chkestopts(options,ncases,nmeas);

if(~isnan(eopts.monteseed(1)))
    randn('state', eopts.monteseed(1));
end

Minv = inv([S;C]);
ns = size(S,1);               % Number of solve-for states
nx = size(Minv,1);            % Total number of states
Stilde = Minv(:,1:ns);

%%
% Pre-allocate cell arrays, but let each pass through the monte carlo loop
% allocate the array for its own case; this allows each worker to allocate
% its own space when using parallel computing.
[t,x,shat,es,Phat,dy,eflag,Pdy] = deal(cell(1,ncases));
hbar = sqrt(3); % spddf scale size = sqrt(3) for Gaussian
% Norgaard (2000) points out that hbar^2 = kurtosis > 1 for all
% distributions

nss=sum(1:ns);

% Covariance analysis.  Looks a lot like the MonteCarlo loop
% Used to be the first loop of the MonteCarlo loop with lots
% of special case code, but was pulled out to aid
% parallelization

t{1} = reshape(repmat(tspan(:)',2,1),1,[]); 
lent = length(t{1});
x{1} = [Xo + covsmpl(Po),NaN(nx,lent-1)];                    % Allocate true states with random i.c. based on Po
shat{1} = [Xbaro,NaN(ns,lent-1)];                                      % Allocate solve-for states, same i.c. each case
es{1} = S*x{1} - shat{1};                                              % Allocate estimation error
Phat{1} = [scrunch(Pbaro), NaN(nss,lent-1)];                           % Allocate estimation error covariance
xhat = [Xo,NaN(nx,lent-1)];                                        % Allocate reference true state
Psa = NaN([size(Pbaro),lent]);                                     % Allocate formal covariance due to a priori
P_a = NaN([size(Po),lent]);                                     % Allocate true covariance of solve-for due to a priori
Pda = NaN([size(Pbaro),lent]);
Psa(:,:,1) = Pbaro;
P_a(:,:,1) = Po;
Pda(:,:,1) = S*P_a(:,:,1)*S' - Psa(:,:,1);                                                   % Allocate difference in covariance
[Psv,Psw] = deal(0*Psa);                                           % Allocate formal variance due to noise
[P_v,P_w] = deal(0*P_a);                                           % Allocate true variance of s due to noise
[Pdv,Pdw] = deal(0*Pda);                                           % Allocate delta variance
rtPssa = chol(Pbaro)';                                             % Initialize sqrt of formal cov
rtPxxa = chol(Po)';                                                % Initialize sqrt of true cov of all states
[rtPssv,rtPssw] = deal(0*rtPssa);                                  % Initialize sqrt of formal cov due to noise
[rtPxxv,rtPxxw] = deal(0*rtPxxa);                                  % Initialize sqrt of true cov due to noise
[eflag{:}] = deal(NaN(nmeas,lent));
[Pdy{:}] = deal(NaN(nmeas,nmeas,lent)); % Measurement innovations covariance


dy{1} = NaN(nmeas,lent); 

for k = 2:2:lent,                                                          % March along in time

    % Measurement Update
    % -------------------
    
    % Perform first case of the Monte Carlo in divided form
    [shat{1}(:,k),dy{1}(:,k),rtPss,Phat{1}(:,k),K,ytru,eflag{1}(:,k),Pdy{1}(:,:,k)]=spf_mu(t{1}(k-1),...
        shat{1}(:,k-1),[rtPssa,rtPssv,rtPssw],...
        measfun,measarg,eopts,hbar,ns,x{1}(:,k-1));
    [rtPssa,rtPssv,rtPssw] = extractdiffs(rtPss,ns);
    
    % Perform true measurement update in divided form 
    L = Stilde*K;                                                          % Project to all states
    [xhat(:,k),~,rtPxx]=spf_mu(t{1}(k-1),...
        xhat(:,k-1),[rtPxxa,rtPxxv,rtPxxw],...
        measfun,measarg,eopts,hbar,nx,x{1}(:,k-1),L,ytru);
    [rtPxxa,rtPxxv,rtPxxw] = extractdiffs(rtPxx,nx);

    % Compute full covariances
    [Psa(:,:,k),Psv(:,:,k),Psw(:,:,k),...
    P_a(:,:,k),P_v(:,:,k),P_w(:,:,k),...
    Pda(:,:,k),Pdv(:,:,k),Pdw(:,:,k)] = ...
            fullcovs(rtPssa,rtPssv,rtPssw,rtPxxa,rtPxxv,rtPxxw,S);

    % Truth "measurement update"
    x{1}(:,k) = x{1}(:,k-1);                                               % Repeat true to match time vector
    es{1}(:,k) = S*x{1}(:,k) - shat{1}(:,k);                               % Diff between true and estimated

    % Time Update
    % -------------
    
    if k<lent
        
        % Formal time update
        tprop = [t{1}(k) t{1}(k+1)];                                       % 2-element time vector
        [shat{1}(:,k+1),rtPss,Phat{1}(:,k+1),x{1}(:,k+1)]=spf_tu(tprop,...
            shat{1}(:,k),[rtPssa rtPssv rtPssw],propfun,proparg,hbar,ns,...
            x{1}(:,k));
        [rtPssa,rtPssv,rtPssw] = extractdiffs(rtPss,ns);
        
        % True time update
        [xhat(:,k+1),rtPxx]=spf_tu(...
            tprop,xhat(:,k),[rtPxxa rtPxxv rtPxxw],propfun,proparg,hbar,nx);
        [rtPxxa,rtPxxv,rtPxxw] = extractdiffs(rtPxx,nx);

        % Compute full covariances
        [Psa(:,:,k+1),Psv(:,:,k+1),Psw(:,:,k+1),...
            P_a(:,:,k+1),P_v(:,:,k+1),P_w(:,:,k+1),...
            Pda(:,:,k+1),Pdv(:,:,k+1),Pdw(:,:,k+1)] = ...
            fullcovs(rtPssa,rtPssv,rtPssw,rtPxxa,rtPxxv,rtPxxw,S);
         es{1}(:,k+1) = S*x{1}(:,k+1) - shat{1}(:,k+1);
    end
end                                                                              % Go through the time span

% MonteCarlo simulations
% Loop starts at 2 because the first MonteCarlo simulation was done at the
% same time as covariance analysis
parfor j = 2:ncases,
    
    if(~isnan(eopts.monteseed(j)))
        randn('state', eopts.monteseed(j)); 
    end

    % Initialize variables 
    t{j} = reshape(repmat(tspan(:)',2,1),1,[]);  %#ok<PFBNS>
    lent = length(t{j});
    x{j} = [Xo + chol(Po)'*randn(nx,1),NaN(nx,lent-1)];                    %#ok<PFOUS> % Allocate true states with random i.c. based on Po
    shat{j} = [Xbaro,NaN(ns,lent-1)];                                      % Allocate solve-for states, same i.c. each case
    es{j} = S*x{j} - shat{j};                                              % Allocate estimation error
    Phat{j} = [scrunch(Pbaro), NaN(nss,lent-1)];                           % Allocate estimation error covariance
    dy{j} = NaN(nmeas,lent);
    
    rtPss = chol(Pbaro)';
     
    for k = 2:2:lent,                                                      % March along in time

        % *ADDSPF Measurement Update*
        %
        % $$ K_i = ... $$
        %
        [shat{j}(:,k),dy{j}(:,k),rtPss,Phat{j}(:,k),~,~,eflag{j}(:,k),Pdy{j}(:,:,k)]=spf_mu(t{j}(k-1),...
            shat{j}(:,k-1),rtPss,...
            measfun,measarg,eopts,hbar,ns,x{j}(:,k-1));

        % Truth "measurement update"
        x{j}(:,k) = x{j}(:,k-1);                                           % Repeat true to match time vector
        es{j}(:,k) = S*x{j}(:,k) - shat{j}(:,k);                           % Diff between true and estimated

        % *ADDSPF Time Update*
        %
        if k<lent
        
            tprop = [t{j}(k) t{j}(k+1)];                                   % 2-element time vector
            [shat{j}(:,k+1),rtPss,Phat{j}(:,k+1),x{j}(:,k+1)]=spf_tu(...
                tprop,shat{j}(:,k),rtPss,propfun,proparg,hbar,ns,x{j}(:,k));
            es{j}(:,k+1) = S*x{j}(:,k+1) - shat{j}(:,k+1);

        end
    end                                                                    % Go through the time span
end

%% Variance Sandpiles
% Generate "variance sandpiles," which are stacked area charts showing the
% the time series of each solve-for variance's contribution from _a
% priori_ error variance, measurement noise variance, and process noise
% variance.  This can be done is several ways.  The true variance and the
% formal variance are
%
% $$ P = P_a + P_v + P_w, \quad \hat{P} = \hat{P}_a + \hat{P}_v $$
%
% and the delta variances are
%
% $$ \Delta P_a = S P_a S' - \hat{P}_a, \quad  \Delta P_v = S P_v S' -
% \hat{P}_v, \quad \Delta P_w = S P_w S' $$
%
% When all the delta variances are positive, the sandpile should show the
% formal variance, and the deltas due to each component.  When all the
% deltas are negative, the sandpile should show the true variance, and
% negatives of the deltas.  Otherwise, plot the components of the true
% variance as a positive sandpile, and the components of the formal
% variance as a negative sandpile, and relabel the negative y-axes to
% indicate this.
%
% NOTE: For the demomode examples plotted below, the pre- and
% post-multiplication of P_a, P_v, and P_w by S and S',
% respectively, have been ignored for simplicity since the
% solve-for states are the first ns states.
if demomode,
    for i = 1:ns,
        vart = squeeze(P_a(i,i,:)+P_v(i,i,:)+P_w(i,i,:))';
        vars = squeeze(Psa(i,i,:)+Psv(i,i,:)+Psw(i,i,:))';
        figure(i)
        clf
        subplot(2,1,1)
        varpiles(t{1},Pda(i,i,:),Pdv(i,i,:),Pdw(i,i,:),...
            P_a(i,i,:),P_v(i,i,:),P_w(i,i,:),...
            Psa(i,i,:),Psv(i,i,:),Psw(i,i,:),...
            vart',vars');
        subplot(2,1,2)
        plot(t{1},ksig*[1;-1]*sqrt(vars),'g--',...
            t{1},ksig*[1;-1]*sqrt(vart),'c--')
%         legend(h([1 3]),['Formal: \pm', num2str(ksig),'-\sigma'], ...
%             ['"True:" \pm', num2str(ksig),'-\sigma'])
        hold on
    end
end

%% Estimation Error Ensemble
if demomode,
    % Need to reset some variables due to non-deterministic nature of
    % parfor loop above:
    j = 0; %#ok<NASGU>
    lent = length(t{1}); 
    ss = std(reshape([es{:}],ns,lent,ncases),0,3);
    for i = 1:ns,
        figure(i)
        subplot(2,1,2)
        plot(t{1},ksig*[1;-1]*ss(i,:),'r--')
        ch = get(gca,'children');
        legend(ch(1:2:5),['Empirical: \pm', num2str(ksig),'-\sigma'], ...
            ['"True:" \pm', num2str(ksig),'-\sigma'],...
            ['Formal: \pm', num2str(ksig),'-\sigma'])
        for j = 1:ncases,
            plot(t{j},es{j}(i,:))
        end
        hold off
        title([num2str(ncases),'-case Monte Carlo'])
    end
    disp('You are in the workspace of ESTSPF; type ''return'' to exit.')
    keyboard
end

% Assign output variables
if nargout >= 3,
    varargout{1} = t;
    varargout{2} = shat;
    varargout{3} = Phat;
end
if nargout >=4,
    varargout{4} = es;
end
if nargout >=5,
    varargout{5} = dy;
end
if nargout >=6,
    varargout{6} = P_a;
end
if nargout >=7,
    varargout{7} = P_v;
end
if nargout >=8,
    varargout{8} = P_w;
end
if nargout >=9,
    varargout{9} = Psa;
end
if nargout >=10,
    varargout{10} = Psv;
end
if nargout >=11,
    varargout{11} = Psw;
end
if nargout >=12,
    varargout{12} = eflag;
end
if nargout >=13,
    varargout{13} = Pdy;
end

end % function

% ESTSPF helper functions

function [shat_pst,dy,rtPss,Phat,K,ytru,eflag,Pzz]=spf_mu(t,...
    shat_pre,rtPss,fun,arg,opt,hbar,ns,x,K,ytru)
% SPF measurement update function
[~,n2] = size(rtPss);
if n2 == ns
    n = ns;
elseif n2 == 3*ns
    n = 3*ns;
    [rtPssa,rtPssv,rtPssw]=extractdiffs(rtPss,ns);
else
    error('Inconsistent rtPss in spf_mu');
end
S_star = spawnsigpts(shat_pre,rtPss,hbar,n);                               % New sigma pts
if nargin < 10
    [Z_mnus,rtR] = feval(fun.est,t,S_star,arg.est);                        % Solve-for meas sigma pts
    zhat = mergesigpts(Z_mnus,hbar,n);
    [ytru,rtV] = feval(fun.tru,t,x,arg.tru);
    ytru = ytru + rtV*randn(length(rtV),1);
    dy = ytru - zhat;
    [Dz_1,Dz_2] = diffsigpts(Z_mnus,hbar,n);
    Pzz = NaN(length(dy),length(dy));
    iy = ~isnan(dy);
    Pzz(iy,iy) = [Dz_1(iy,:) Dz_2(iy,:) rtR(iy,iy)]*[Dz_1(iy,:) Dz_2(iy,:) rtR(iy,iy)]';
    Psz = rtPss*Dz_1';                                                     % Cross-correlation
    [process,eflag] = editmeas(true(size(dy)),dy,Pzz,opt.eflag,opt.eratio);
    ikeep = find(process == true);
    K = zeros(ns,length(dy));
    K(:,ikeep) = Psz(:,ikeep)/Pzz(ikeep,ikeep); % Compute gains only for measurements that will be used
else
    [Z_mnus,rtR] = feval(fun.tru,t,S_star,arg.tru);                        % True meas sigma pts
    zhat = mergesigpts(Z_mnus,hbar,n);
    [Dz_1,Dz_2] = diffsigpts(Z_mnus,hbar,n);
end

[dy,K] = fixgain(ytru,zhat,K);
iuse=find(~isnan(dy));
shat_pst = shat_pre + K(:,iuse)*dy(iuse);

if n == ns
    rtPss = thinQR([rtPss-K*Dz_1, K*[Dz_2 rtR]],ns);                       % Sqrt of solve-for covariance
    Phat = scrunch(rtPss*rtPss');
else
    [Dza1,Dzv1,Dzw1] = extractdiffs(Dz_1,ns);
    [Dza2,Dzv2,Dzw2] = extractdiffs(Dz_2,ns);
    rtPssa = thinQR([rtPssa-K*Dza1, K*Dza2],ns);
    rtPssv = thinQR([rtPssv-K*Dzv1, K*[Dzv2 rtR]],ns);
    rtPssw = thinQR([rtPssw-K*Dzw1, K*Dzw2],ns);
    rtPss = [rtPssa rtPssv rtPssw];
    Phat = scrunch(rtPssa*rtPssa' + rtPssv*rtPssv' + rtPssw*rtPssw');
end

end % function


function [shat_pst,rtPss,Phat,x_pst]=spf_tu(...
    tprop,shat_pre,rtPss,fun,arg,hbar,ns,x_pre)
% SPF time update function
[~,n2] = size(rtPss);
if n2 == ns
    n = ns;
elseif n2 == 3*ns
    n = 3*ns;
else
    error('Inconsistent rtPss in spf_tu');
end

S_last = spawnsigpts(shat_pre,rtPss,hbar,n);                               % Sigma pts

if nargin > 7
    [x_pst,rtWd] = feval(fun.tru,tprop,x_pre,arg.tru);
    wd = rtWd*randn(size(x_pre));
    x_pst = x_pst + wd;                                                    % Random process noise added to truth
    [S_mnus,rtQd] = feval(fun.est,tprop,S_last,arg.est);                   % Propagate estimator sigma pts
else
    [S_mnus,rtQd] = feval(fun.tru,tprop,S_last,arg.tru);                   % Propagate true sigma pts
end

[Ds_1,Ds_2] = diffsigpts(S_mnus,hbar,n);                                   % Num diff of prop sig pts
shat_pst = mergesigpts(S_mnus,hbar,n);                                     % Combine propagated sig pts

% Propagated square root of the covariance partitions
if n == ns
    rtPss = thinQR([Ds_1 Ds_2 rtQd],ns);
    Phat = scrunch(rtPss*rtPss');
else
    [Dsa1,Dsv1,Dsw1] = extractdiffs(Ds_1,ns);
    [Dsa2,Dsv2,Dsw2] = extractdiffs(Ds_2,ns);
    rtPssa = thinQR([Dsa1 Dsa2],ns);
    rtPssv = thinQR([Dsv1 Dsv2],ns);
    rtPssw = thinQR([Dsw1 Dsw2 rtQd],ns);
    rtPss = [rtPssa rtPssv rtPssw];
    Phat = scrunch(rtPssa*rtPssa' + rtPssv*rtPssv' + rtPssw*rtPssw');
end

end % function

function X = spawnsigpts(x,N,hbar,n)
% Creates the set of sigma points from the mean, x, the Cholesky factor
% of the covariance matrix, N, and the divided difference scale factor, hbar.
% The resulting set is returned as a matrix, X, whose first column is x,
% whose 2nd:nth columns are x+hN, and whose n+st1:2nth columns are x-hN.
X = repmat(x,1,2*n+1) + [zeros(size(x)), hbar*N, -hbar*N];

end % function

function x = mergesigpts(X,hbar,n)
% Merge a set of sigma points back into a single vector.
x = (hbar^2-n)/hbar^2*X(:,1) + sum(1/2/hbar^2*X(:,2:end),2);

end % function

function [D1,D2] = diffsigpts(X,hbar,n)
% Compute the divided difference matrices containing information about the
% first and second derivatives of a set of sigma points, S1 and S2,
% respectively.
for i = n:-1:1,
    D1(:,i) = 1/2/hbar*(X(:,i+1) - X(:,i+n+1)); 
    D2(:,i) = sqrt(hbar^2-1)/2/hbar^2*(X(:,i+1) + X(:,i+n+1) - 2*X(:,1)); 
end
n1 = isnan(D1);
n2 = isnan(D2);
if any(n1),
    D1(n1) = 0;
end
if any(n2),
    D2(n2) = 0;
end

end % function

function [Da,Dv,Dw] = extractdiffs(D,n)
% Extract columns from the divided difference matrices that corresponds to
% the covariance partitions.
Da = D(:,    1:  n);
Dv = D(:,  n+1:2*n);
Dw = D(:,2*n+1:3*n);

end % function

function [omc,K] = fixgain(observed,computed,K)
% For any observed minus computed measurements that are NaNs due to 
% measurement unavailability, set the corresponding columns of the gain 
% matrix K to zero.
omc = observed - computed;
n = isnan(omc);
if any(n),
    K(:,n) = 0;
end

end % function

function N = thinQR(D,n)
% Perform "thin" QR decomposition of the compound matrix.  For rectangular
% inputs, Matlab's QR function returns a rectanglar upper triangular
% matrix and a square unitary matrix; Golub & Van Loan call this the "full"
% QR decomposition.  They point out that the input can equivalently be
% factorized into a square upper triangular matrix and a rectangular
% orthogonal matrix, which they call the "thin" QR decomposition.  This is
% what we need here.  To trick Matlab, we have to transpose the input
% matrix.  This produces an upper triangular rectangular matrix, as usual,
% but the bottom of it is all zero rows, and if we remove these, we get the
% transpose of the square triangular matrix we need (which will now be
% lower, not upper triangular, but this is OK, since Matlab also defines
% the Cholesky decomposition as P=S'*S rather than P=S*S').
% (Incidentally, by pure chance I once shared a cab with Gene Golub.  We
% had both attended the 2001 SIAM control conference in San Diego, and
% since there was a line afterwards to get a cab to the airport, I just
% asked the guy in front of me if we could share, not having any idea who he
% was.  He said sure, and on the way over introduced himself like this:
% "I'm Gene Golub, maybe you've read the book Charlie van Loan and I wrote?"
if D == 0,
    N = zeros(n,n);
else
    N = triu(qr(D'));
    N = N(1:n,:)';
end

end % function

function [Psa,Psv,Psw,P_a,P_v,P_w,Pda,Pdv,Pdw] = fullcovs(...
    rtPssa,rtPssv,rtPssw,rtPxxa,rtPxxv,rtPxxw,S)
% Create full covariances from Cholesky factors for output
Psa = rtPssa*rtPssa';
Psv = rtPssv*rtPssv';
Psw = rtPssw*rtPssw';
P_a = rtPxxa*rtPxxa';
P_v = rtPxxv*rtPxxv';
P_w = rtPxxw*rtPxxw';
Pda = S*P_a*S' - Psa;
Pdv = S*P_v*S' - Psv;
Pdw = S*P_w*S' - Psw;

end % function